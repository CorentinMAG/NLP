{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bidaf_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1E8UcRYR1BlmgRH_ipWm2paY2qj-IJ_6Q",
      "authorship_tag": "ABX9TyMqnJ0K1hJDM4xnCESuNqEx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CorentinMAG/NLP/blob/main/BIDAF/bidaf_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hvai4UxyMH1S"
      },
      "source": [
        "a very good explanation of the BIDAF architecture : \r\n",
        "\r\n",
        "https://towardsdatascience.com/the-definitive-guide-to-bi-directional-attention-flow-d0e96e9e666b\r\n",
        "\r\n",
        "character embedding with CNN :\r\n",
        "\r\n",
        "https://towardsdatascience.com/besides-word-embedding-why-you-need-to-know-character-embedding-6096a34a3b10\r\n",
        "https://github.com/makcedward/nlp/blob/master/sample/nlp-character_embedding.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcJDYwmpauq3"
      },
      "source": [
        "To run this notebook you should have run the bidaf_preprocessing one.  \r\n",
        "You should as well modify all paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8tAi2rmMp_h",
        "outputId": "1b1a6820-2db5-4b49-8e7b-c6c400f2df40"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import pandas as pd\r\n",
        "import os\r\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Bidirectional, TimeDistributed\r\n",
        "from tensorflow.keras.layers import Layer, Softmax, Concatenate, Dropout, Conv1D, GlobalMaxPooling1D\r\n",
        "from tensorflow.keras.backend import batch_dot\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "import tensorflow.keras.backend as K\r\n",
        "tf.get_logger().setLevel('INFO')\r\n",
        "from tqdm import tqdm\r\n",
        "import numpy as np\r\n",
        "import pickle\r\n",
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "import gensim.downloader as gloader\r\n",
        "import math\r\n",
        "\r\n",
        "try:\r\n",
        "  from utils.datasets import SQUAD_dataset\r\n",
        "except:\r\n",
        "  import sys\r\n",
        "  sys.path.append(os.path.join(os.getcwd(),'drive/MyDrive/NLP/BIDAF'))\r\n",
        "  from utils.datasets import SQUAD_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJiZBATwVsHR"
      },
      "source": [
        "path_word_tokenizer = os.path.join(os.getcwd(),'drive/MyDrive/NLP/BIDAF/utils', 'tokenizers/word_tokenizer.pkl')\r\n",
        "with open(path_word_tokenizer, 'rb') as handle:\r\n",
        "  tokenizer = pickle.load(handle)\r\n",
        "\r\n",
        "path_char_tokenizer = os.path.join(os.getcwd(), 'drive/MyDrive/NLP/BIDAF/utils', 'tokenizers/char_tokenizer.pkl')\r\n",
        "with open(path_char_tokenizer, 'rb') as char_handle:\r\n",
        "  char_tokenizer = pickle.load(char_handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNsokDe-Lk6f"
      },
      "source": [
        "train_dataset = SQUAD_dataset.from_file('drive/MyDrive/NLP/BIDAF/utils/datasets/train_dataset.pkl')\r\n",
        "valid_dataset = SQUAD_dataset.from_file('drive/MyDrive/NLP/BIDAF/utils/datasets/valid_dataset.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzg9Gv7gMcIe",
        "outputId": "e6db3fee-5255-4075-8916-96dd61d3d19e"
      },
      "source": [
        "train_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SQUAD_dataset : questions : (10, 25), contexts : (10, 400), char_questions : (10, 25, 15), char_contexts : (10, 400, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANbgqwjsMfBK",
        "outputId": "14d00987-f54f-475c-eb2e-61781b3b84c3"
      },
      "source": [
        "print(len(train_dataset))\r\n",
        "len(valid_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6961\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1742"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68jUK4Q-M8ur"
      },
      "source": [
        "QUESTION_MAXLEN = 25\r\n",
        "CONTEXT_MAXLEN = 400\r\n",
        "EMBEDDING_SIZE = 300 # we can try different embedding size (50, 100, 300) or even try word2vec or fastext instead of glove\r\n",
        "WORD_VOCAB_LEN = len(tokenizer.word_index) + 1 # +1 for the pad token\r\n",
        "BATCH_SIZE = 10\r\n",
        "EPOCHS = 10\r\n",
        "CHAR_VOCAB_LEN = char_tokenizer.num_words # PAD token and UNK token included\r\n",
        "WORD_MAXLEN = 15\r\n",
        "LR = 0.0005\r\n",
        "N_FILTERS = EMBEDDING_SIZE\r\n",
        "FILTER_SIZE = 3\r\n",
        "CHAR_EMBEDDING_SIZE = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeQ8obxkV-y1"
      },
      "source": [
        "def download_glove_embedding(embedding_dimension = 50):\r\n",
        "  download_path = 'glove-wiki-gigaword-{}'.format(embedding_dimension)\r\n",
        "  try:\r\n",
        "    emb_model = gloader.load(download_path)\r\n",
        "  except ValueError as e:\r\n",
        "      print('Glove: 50, 100, 200, 300')\r\n",
        "      raise e\r\n",
        "  return emb_model\r\n",
        "\r\n",
        "def build_embedding_matrix(tokenizer,glove_model = None):\r\n",
        "\r\n",
        "  if glove_model == None:\r\n",
        "    glove_model = download_glove_embedding(EMBEDDING_SIZE)\r\n",
        "\r\n",
        "  embedding_matrix = np.zeros((WORD_VOCAB_LEN, EMBEDDING_SIZE))\r\n",
        "\r\n",
        "  for w,i in tokenizer.word_index.items():\r\n",
        "\r\n",
        "    if w in glove_model.vocab:\r\n",
        "      embedding_matrix[i,:] = glove_model.get_vector(w)\r\n",
        "    else:\r\n",
        "      embedding_matrix[i,:] = np.random.randn(1, EMBEDDING_SIZE)\r\n",
        "\r\n",
        "  del glove_model # we don't need it anymore\r\n",
        "\r\n",
        "  return embedding_matrix\r\n",
        "\r\n",
        "def build_char_embedding_matrix(char_tokenizer):\r\n",
        "\r\n",
        "  char_embedding_matrix = np.zeros((CHAR_VOCAB_LEN,CHAR_VOCAB_LEN - 1))  # we have 199 characters that we have to one hot so each character has 199 dimensions\r\n",
        "\r\n",
        "  for char, i in char_tokenizer.word_index.items():\r\n",
        "    if i <= 199:\r\n",
        "      char_embedding_matrix[i][i - 1] = 1\r\n",
        "    else:\r\n",
        "      break\r\n",
        "  return char_embedding_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTL3GYD2TsrV"
      },
      "source": [
        "We build the embedding matrix.  \r\n",
        "We can also initialize a char_embedding_matrix, or we can let the model learn these embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Jkm1-RRXypA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07bd22f3-7c9b-40b2-e142-83aa7ffaa435"
      },
      "source": [
        "embedding_matrix = build_embedding_matrix(tokenizer)\r\n",
        "\r\n",
        "# instead of one hot encode char tokens maybe we can use glove or randomly fill the matrix\r\n",
        "# these embeddings should be trainable\r\n",
        "# https://github.com/minimaxir/char-embeddings\r\n",
        "#char_embedding_matrix = build_char_embedding_matrix(char_tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[===============================================---] 95.5% 359.0/376.1MB downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2rjHEDUTvv4"
      },
      "source": [
        "Then we define all layers of our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00VHMy09YmOp"
      },
      "source": [
        "# utils/layers\r\n",
        "class WordEmbedding(Layer):\r\n",
        "    \r\n",
        "    def __init__(self, input_dim, output_dim, input_len, embedding_matrix, trainable = False, mask_zero = True, **kwargs):\r\n",
        "        \r\n",
        "        super(WordEmbedding, self).__init__(**kwargs)\r\n",
        "\r\n",
        "        self.input_dim = input_dim\r\n",
        "        self.output_dim = output_dim\r\n",
        "        self.input_len = input_len\r\n",
        "        self.embedding_matrix = embedding_matrix\r\n",
        "        self.trainable = trainable\r\n",
        "        self.mask_zero = mask_zero\r\n",
        "\r\n",
        "        self.word_embed = Embedding(\r\n",
        "            input_dim = self.input_dim,\r\n",
        "            output_dim = self.output_dim,\r\n",
        "            weights = [self.embedding_matrix],\r\n",
        "            trainable = self.trainable,\r\n",
        "            input_length = self.input_len,\r\n",
        "            mask_zero = self.mask_zero,\r\n",
        "        )\r\n",
        "\r\n",
        "    def build(self, input_shape):\r\n",
        "      self.built = True\r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "        input = inputs\r\n",
        "        return self.word_embed(input) \r\n",
        "    \r\n",
        "    # inplement this method in order to get a serializable layer as part of a Functional model\r\n",
        "    def get_config(self):\r\n",
        "        # the base Layer class takes some keywords arguments like name and dtype, it is good to include \r\n",
        "        # them in the config (so we call the parent method and use the update method)\r\n",
        "        config = super().get_config().copy()\r\n",
        "        config.update({\r\n",
        "            'input_dim': self.input_dim,\r\n",
        "            'output_dim': self.output_dim,\r\n",
        "            'input_len': self.input_len, \r\n",
        "            'trainable': self.trainable,\r\n",
        "            'mask_zero': self.mask_zero\r\n",
        "        })\r\n",
        "        return config\r\n",
        "\r\n",
        "    @classmethod\r\n",
        "    def from_config(cls, config):\r\n",
        "      return cls(**config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueuhbaJjsYVe"
      },
      "source": [
        "# utils/layers\r\n",
        "class CharEmbedding(Layer):\r\n",
        "    \r\n",
        "    def __init__(self, input_dim, output_dim, input_len, **kwargs):\r\n",
        "        \r\n",
        "        super(CharEmbedding, self).__init__(**kwargs)\r\n",
        "\r\n",
        "        self.input_dim = input_dim\r\n",
        "        self.output_dim = output_dim\r\n",
        "        self.input_len = input_len\r\n",
        "        self.char_embed = Embedding(\r\n",
        "            input_dim = self.input_dim, \r\n",
        "            output_dim = self.output_dim,  \r\n",
        "            input_length = self.input_len\r\n",
        "        )\r\n",
        "        # This wrapper allows to apply a layer to every temporal slice of an input.\r\n",
        "        # so we apply the same Embedding to every timestep (index 1) independently\r\n",
        "        self.timed = TimeDistributed(self.char_embed)\r\n",
        "        \r\n",
        "\r\n",
        "    def build(self, input_shape):\r\n",
        "        self.built = True\r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "        return self.timed(inputs)\r\n",
        "            \r\n",
        "    def get_config(self):\r\n",
        "\r\n",
        "        config = super().get_config().copy()\r\n",
        "        config.update({\r\n",
        "            'input_dim': self.input_dim,\r\n",
        "            'output_dim': self.output_dim,\r\n",
        "            'input_len': self.input_len, \r\n",
        "        })\r\n",
        "        return config\r\n",
        "\r\n",
        "    @classmethod\r\n",
        "    def from_config(cls, config):\r\n",
        "      return cls(**config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8R7tBTZskqP"
      },
      "source": [
        "# utils/layers\r\n",
        "class CharCNN(Layer):\r\n",
        "    \r\n",
        "    def __init__(self, n_filters, filter_width, **kwargs):\r\n",
        "        \r\n",
        "        super(CharCNN, self).__init__(**kwargs)\r\n",
        "        self.n_filters = n_filters\r\n",
        "        self.filter_width = filter_width\r\n",
        "        self.conv = Conv1D(self.n_filters, self.filter_width)\r\n",
        "        self.pool = GlobalMaxPooling1D()\r\n",
        "        self.timed = TimeDistributed(self.pool)\r\n",
        "          \r\n",
        "    def build(self, input_shape):\r\n",
        "        self.built = True\r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "        return self.timed(self.conv(inputs))\r\n",
        "    \r\n",
        "    def get_config(self):\r\n",
        "\r\n",
        "        config = super().get_config().copy()\r\n",
        "        config.update({\r\n",
        "            'n_filters': self.n_filters,\r\n",
        "            'filter_width': self.filter_width, \r\n",
        "        })\r\n",
        "        return config\r\n",
        "\r\n",
        "    @classmethod\r\n",
        "    def from_config(cls, config):\r\n",
        "      return cls(**config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p36emvbtYtj-"
      },
      "source": [
        "# utils/layers\r\n",
        "class HighwayNetwork(Layer):\r\n",
        "    \r\n",
        "    def __init__(self, hidden_size, **kwargs):\r\n",
        "        \r\n",
        "        super(HighwayNetwork, self).__init__(**kwargs)\r\n",
        "        self.hidden_size = hidden_size\r\n",
        "        self.normal = Dense(self.hidden_size, activation = 'relu') \r\n",
        "        self.transform_gate = Dense(self.hidden_size, activation = 'sigmoid')\r\n",
        "        \r\n",
        "    def build(self, input_shape):\r\n",
        "        self.built = True\r\n",
        "\r\n",
        "    def call(self, inputs):        \r\n",
        "        \r\n",
        "        n = self.normal(inputs)\r\n",
        "        g = self.transform_gate(inputs)\r\n",
        "        x = g*n + (1-g)*inputs \r\n",
        "        return x\r\n",
        "\r\n",
        "    def get_config(self):\r\n",
        "\r\n",
        "        config = super().get_config().copy()\r\n",
        "        config.update({\r\n",
        "            'hidden_size': self.hidden_size, \r\n",
        "        })\r\n",
        "        return config\r\n",
        "\r\n",
        "    @classmethod\r\n",
        "    def from_config(cls, config):\r\n",
        "      return cls(**config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ci1m5TSYvjQ"
      },
      "source": [
        "# utils/layers\r\n",
        "class ContextualEmbedding(Layer):\r\n",
        "    \r\n",
        "    def __init__(self, output_dim, **kwargs):\r\n",
        "        \r\n",
        "        super(ContextualEmbedding, self).__init__(**kwargs)\r\n",
        "        self.output_dim = output_dim\r\n",
        "        self.contextual = Bidirectional(LSTM(self.output_dim, return_sequences = True, dropout = 0.2))\r\n",
        "\r\n",
        "    def build(self, input_shape):\r\n",
        "        self.built = True \r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "        return self.contextual(inputs)\r\n",
        "    \r\n",
        "    def get_config(self):\r\n",
        "\r\n",
        "        config = super().get_config().copy()\r\n",
        "        config.update({\r\n",
        "            'output_dim': self.output_dim,\r\n",
        "        })\r\n",
        "        return config\r\n",
        "    \r\n",
        "    @classmethod\r\n",
        "    def from_config(cls, config):\r\n",
        "      return cls(**config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58s56NipY-s-"
      },
      "source": [
        "# utils/layers\r\n",
        "class Modelling(Layer):\r\n",
        "    \r\n",
        "    def __init__(self, output_dim, **kwargs):\r\n",
        "        \r\n",
        "        super(Modelling, self).__init__(**kwargs)\r\n",
        "        self.output_dim = output_dim\r\n",
        "        self.modelling1 = Bidirectional(LSTM(self.output_dim, return_sequences = True, dropout = 0.2))\r\n",
        "        self.modelling2 = Bidirectional(LSTM(self.output_dim, return_sequences = True, dropout = 0.2))\r\n",
        "        \r\n",
        "    def build(self, input_shape):\r\n",
        "        self.built = True\r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "        return self.modelling2(self.modelling1(inputs))\r\n",
        "    \r\n",
        "    def get_config(self):\r\n",
        "\r\n",
        "        config = super().get_config().copy()\r\n",
        "        config.update({\r\n",
        "            'output_dim': self.output_dim,\r\n",
        "        })\r\n",
        "        return config\r\n",
        "\r\n",
        "    @classmethod\r\n",
        "    def from_config(cls, config):\r\n",
        "      return cls(**config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPIvap9IZCMS"
      },
      "source": [
        "# utils/layers\r\n",
        "class Start(Layer):\r\n",
        "    \r\n",
        "    def __init__(self, **kwargs):\r\n",
        "        \r\n",
        "        super(Start, self).__init__(**kwargs)\r\n",
        "        self.dense = Dense(1, activation = 'linear', use_bias = False)\r\n",
        "        self.dropout = Dropout(0.2)\r\n",
        "        \r\n",
        "    def build(self, input_shape):\r\n",
        "        self.built = True\r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "        \r\n",
        "        GM = inputs\r\n",
        "        start = self.dense(GM)\r\n",
        "        start = self.dropout(start)\r\n",
        "        p1 = tf.nn.softmax(tf.squeeze(start, axis = 2))\r\n",
        "        return p1\r\n",
        "\r\n",
        "    def get_config(self):\r\n",
        "      \r\n",
        "      config = super().get_config().copy()\r\n",
        "      return config\r\n",
        "\r\n",
        "    @classmethod\r\n",
        "    def from_config(cls, config):\r\n",
        "      return cls(**config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JumPbG69ZEPf"
      },
      "source": [
        "# utils/layers\r\n",
        "class ModellingEnd(Layer):\r\n",
        "    \r\n",
        "    def __init__(self, output_dim, **kwargs):\r\n",
        "        \r\n",
        "        super(ModellingEnd, self).__init__(**kwargs)\r\n",
        "        self.output_dim = output_dim\r\n",
        "        self.end = Bidirectional(LSTM(self.output_dim, return_sequences = True, dropout = 0.2))\r\n",
        "        \r\n",
        "    def build(self, input_shape):\r\n",
        "        self.built = True\r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "        \r\n",
        "        G, M = inputs\r\n",
        "        M2 = self.end(M)\r\n",
        "        GM2 = tf.concat([G, M2], axis = 2)\r\n",
        "        return GM2\r\n",
        "    \r\n",
        "    def get_config(self):\r\n",
        "\r\n",
        "        config = super().get_config().copy()\r\n",
        "        config.update({\r\n",
        "            'output_dim': self.output_dim,\r\n",
        "        })\r\n",
        "        return config\r\n",
        "\r\n",
        "    @classmethod\r\n",
        "    def from_config(cls, config):\r\n",
        "      return cls(**config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HdLF0UTZGRx"
      },
      "source": [
        "# utils/layers\r\n",
        "class End(Layer):\r\n",
        "    \r\n",
        "    def __init__(self, **kwargs):\r\n",
        "        \r\n",
        "        super(End, self).__init__(**kwargs)\r\n",
        "        self.dense = Dense(1, activation = 'linear', use_bias = False)\r\n",
        "        self.dropout = Dropout(0.2)\r\n",
        "        \r\n",
        "    def build(self, input_shape):\r\n",
        "        self.built = True\r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "        \r\n",
        "        GM2 = inputs\r\n",
        "        end = self.dense(GM2)\r\n",
        "        end = self.dropout(end)\r\n",
        "        p2 = tf.nn.softmax(tf.squeeze(end, axis = 2))\r\n",
        "        \r\n",
        "        return p2\r\n",
        "\r\n",
        "\r\n",
        "    def get_config(self):\r\n",
        "\r\n",
        "      config = super().get_config().copy()\r\n",
        "\r\n",
        "      return config\r\n",
        "    \r\n",
        "    @classmethod\r\n",
        "    def from_config(cls, config):\r\n",
        "      return cls(**config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oj0lLdm_FmX"
      },
      "source": [
        "# utils/models\r\n",
        "class BIDAF(Model):\r\n",
        "\r\n",
        "  def __init__(self, \r\n",
        "               question_maxlen, \r\n",
        "               context_maxlen, \r\n",
        "               word_vocab_len, \r\n",
        "               embedding_size, \r\n",
        "               embedding_matrix, \r\n",
        "               char_vocab_len = None,\r\n",
        "               word_maxlen = None, \r\n",
        "               n_filters = None, \r\n",
        "               filter_size = None, \r\n",
        "               char_embedding_size = None, \r\n",
        "               **kwargs):\r\n",
        "    \r\n",
        "    \r\n",
        "    super(BIDAF, self).__init__(name = 'BIDAF', **kwargs)\r\n",
        "\r\n",
        "    self.question_maxlen = question_maxlen\r\n",
        "    self.contect_maxlen = context_maxlen\r\n",
        "    self.word_vocab_len = word_vocab_len\r\n",
        "    self.embedding_size = embedding_size\r\n",
        "    self.embedding_matrix = embedding_matrix\r\n",
        "    self.char_vocab_len = char_vocab_len\r\n",
        "    self.char_embedding_size = char_embedding_size\r\n",
        "    self.word_max_len = word_maxlen\r\n",
        "    self.n_filters = n_filters\r\n",
        "    self.filter_size = filter_size\r\n",
        "\r\n",
        "    self.similarity_weights = Dense(1, use_bias = False)\r\n",
        "\r\n",
        "    # layers\r\n",
        "    self.word_embedding = WordEmbedding(self.word_vocab_len, self.embedding_size, self.question_maxlen, self.embedding_matrix)\r\n",
        "    self.char_embedding = CharEmbedding(self.char_vocab_len, self.char_embedding_size, self.word_max_len)\r\n",
        "    self.cnn = CharCNN(self.n_filters, self.filter_size)\r\n",
        "    self.highway = HighwayNetwork(hidden_size = self.embedding_size + self.n_filters)\r\n",
        "    self.contextual = ContextualEmbedding(self.embedding_size)\r\n",
        "    self.modelling = Modelling(self.embedding_size)\r\n",
        "    self.modelling_end = ModellingEnd(self.embedding_size)\r\n",
        "    self.output_start = Start()\r\n",
        "    self.ouput_end = End()\r\n",
        "\r\n",
        "  def call(self, inputs, training = True):\r\n",
        "    qw, cw, qc, cc = inputs  # (bs, q_len), (bs, ctx_len), (bs, q_len, w_len), (bs, ctx_len, w_len)\r\n",
        "\r\n",
        "    # embedding always non-trainable\r\n",
        "    qw = self.word_embedding(qw) # (bs, q_len, emb)\r\n",
        "    cw = self.word_embedding(cw) # (bs, ctx_len, emb)\r\n",
        "\r\n",
        "    qc = self.char_embedding(qc) # (bs, q_len, w_len, char_emb)\r\n",
        "    cc = self.char_embedding(cc) # (bs, ctx_len, w_len, char_emb)\r\n",
        "\r\n",
        "    qc = self.cnn(qc) # (bs, q_len, n_filters)\r\n",
        "    cc = self.cnn(cc) # (bs, ctx_len, n_filters)\r\n",
        "\r\n",
        "    H = tf.concat([cw, cc], axis = 2) # (bs, ctx_len, emb + n_filters)\r\n",
        "    U = tf.concat([qw, qc], axis = 2) # (bs, q_len, emb + n_filters)\r\n",
        "\r\n",
        "    # highway\r\n",
        "    H = self.highway(H) # (bs, ctx_len, emb + n_filters)\r\n",
        "    U = self.highway(U) # (bs, q_len, emb + n_filters)\r\n",
        "\r\n",
        "    # contextual embedding\r\n",
        "    H = self.contextual(H) # (bs, ctx_len, emb + n_filters)\r\n",
        "    U = self.contextual(U) # (bs, q_len, emb + n_filters)\r\n",
        "\r\n",
        "    # similarity matrix\r\n",
        "    expand_h = tf.concat([[1, 1], [tf.shape(U)[1]], [1]], axis = 0) # [1, 1, q_len, 1]\r\n",
        "    expand_u = tf.concat([[1], [tf.shape(H)[1]], [1, 1]], axis = 0) # [1, ctx_len, 1, 1]\r\n",
        "\r\n",
        "    h = tf.tile(tf.expand_dims(H, axis = 2), expand_h) # (bs, ctx_len, q_len, emb + n_filters)\r\n",
        "    u = tf.tile(tf.expand_dims(U, axis = 1), expand_u) # (bs, ctx_len, q_len, emb + n_filters)\r\n",
        "    h_u = h * u # (bs, ctx_len, q_len, emb + n_filters)\r\n",
        "\r\n",
        "    alpha = tf.concat([h, u, h_u], axis = -1) # (bs, ctx_len, q_len, 3 * (emb + n_filters))\r\n",
        "    \r\n",
        "    similarity_matrix = self.similarity_weights(alpha) # (bs, ctx_len, q_len, 1)\r\n",
        "    similarity_matrix = tf.squeeze(similarity_matrix, 3) # (bs, ctx_len, q_len)\r\n",
        "\r\n",
        "    # context to query attention\r\n",
        "    attention_weights = tf.nn.softmax(similarity_matrix, axis = -1) # (bs, ctx_len, q_len)\r\n",
        "    C2Q = batch_dot(attention_weights, U) # (bs, ctx_len, emb + n_filters)\r\n",
        "\r\n",
        "    # query to context attention\r\n",
        "    attention_weights = tf.nn.softmax(tf.math.reduce_max(similarity_matrix, axis = 2), axis = -1) # (bs, ctx_len)\r\n",
        "    attention_weights = tf.expand_dims(attention_weights, axis = 1) # (bs, 1, ctx_len)\r\n",
        "    Q2C = batch_dot(attention_weights, H) # (bs, 1, emb + n_filters)\r\n",
        "    Q2C = tf.tile(Q2C, [1, tf.shape(H)[1], 1]) # (bs, ctx_len, emb + n_filters)\r\n",
        "\r\n",
        "    # query aware representation\r\n",
        "    G = tf.concat([H, C2Q, (H * C2Q), (H * Q2C)], axis = 2) # (bs, ctx_len, 4 * (emb + n_filters) )\r\n",
        "\r\n",
        "    # modelling\r\n",
        "    M = self.modelling(G) # (bs, ctx_len, emb + n_filters)\r\n",
        "\r\n",
        "    # output\r\n",
        "    M2 = self.modelling_end([G,M]) # (bs, ctx_len, emb + n_filters)\r\n",
        "\r\n",
        "    # start prediction\r\n",
        "    start = self.output_start(tf.concat([G, M], axis = 2)) # (bs, ctx_len)\r\n",
        "\r\n",
        "    # end prediction\r\n",
        "    end = self.ouput_end(M2) # (bs, ctx_len)\r\n",
        "\r\n",
        "    return start, end"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKicRfIW6tUm"
      },
      "source": [
        "bidaf_model = BIDAF(\r\n",
        "    QUESTION_MAXLEN,\r\n",
        "    CONTEXT_MAXLEN,\r\n",
        "    WORD_VOCAB_LEN,\r\n",
        "    EMBEDDING_SIZE,\r\n",
        "    embedding_matrix,\r\n",
        "    CHAR_VOCAB_LEN,\r\n",
        "    WORD_MAXLEN,\r\n",
        "    N_FILTERS,\r\n",
        "    FILTER_SIZE,\r\n",
        "    CHAR_EMBEDDING_SIZE,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krJp-At4b0y_"
      },
      "source": [
        "loss_function = tf.keras.losses.CategoricalCrossentropy(reduction = 'auto')\r\n",
        "optimizer = tf.keras.optimizers.Nadam(learning_rate = LR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg2EI6tBcbB8"
      },
      "source": [
        "# https://udai.gitbook.io/practical-ml/nn/training-and-debugging-of-nn <- useful blog about machine learning / deep learning\r\n",
        "# steps to be performed in each training step\r\n",
        "@tf.function\r\n",
        "def train_step(model, input_vector, output_vector, loss_fn):\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "        # forward propagation\r\n",
        "        output_predicted = model(input_vector, training = True)\r\n",
        "        # loss\r\n",
        "        loss_start = loss_function(output_vector[0], output_predicted[0])\r\n",
        "        loss_end = loss_function(output_vector[1], output_predicted[1])\r\n",
        "        loss_final = loss_start + loss_end\r\n",
        "    # getting gradients\r\n",
        "    gradients = tape.gradient(loss_final, model.trainable_variables)\r\n",
        "    # applying gradients\r\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n",
        "    return loss_start, loss_end, output_predicted, gradients"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTNI3WKaciDu"
      },
      "source": [
        "# https://udai.gitbook.io/practical-ml/nn/training-and-debugging-of-nn\r\n",
        "# steps to be performed in each validation step\r\n",
        "@tf.function\r\n",
        "def val_step(model, input_vector, output_vector, loss_fn):\r\n",
        "    # getting output of validation data\r\n",
        "    output_predicted = model(input_vector, training = False)\r\n",
        "    # loss calculation\r\n",
        "    loss_start = loss_function(output_vector[0], output_predicted[0])\r\n",
        "    loss_end = loss_function(output_vector[1], output_predicted[1])\r\n",
        "    return loss_start, loss_end, output_predicted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6on5ZTXwZING"
      },
      "source": [
        "def f1_score(y_true, y_pred):    # taken from old keras source code\r\n",
        "    \r\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\r\n",
        "    \r\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\r\n",
        "    \r\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\r\n",
        "    \r\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\r\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\r\n",
        "    \r\n",
        "    f1_val = 2 * (precision * recall) / (precision + recall + K.epsilon())\r\n",
        "    \r\n",
        "    return f1_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmKsimsMcoHu"
      },
      "source": [
        "# defining functions to compute the mean loss for each epoch\r\n",
        "train_start_loss = tf.keras.metrics.Mean(name = 'train_start_loss')\r\n",
        "train_end_loss = tf.keras.metrics.Mean(name = 'train_end_loss')\r\n",
        "val_start_loss = tf.keras.metrics.Mean(name = 'val_start_loss')\r\n",
        "val_end_loss = tf.keras.metrics.Mean(name = 'val_end_loss')\r\n",
        "train_start_f1 = tf.keras.metrics.Mean(name = 'train_start_f1')\r\n",
        "train_end_f1 = tf.keras.metrics.Mean(name = 'train_end_f1')\r\n",
        "val_start_f1 = tf.keras.metrics.Mean(name = 'val_start_f1')\r\n",
        "val_end_f1 = tf.keras.metrics.Mean(name = 'val_end_f1')\r\n",
        "train_start_acc = tf.keras.metrics.CategoricalAccuracy(name = 'train_start_acc')\r\n",
        "train_end_acc = tf.keras.metrics.CategoricalAccuracy(name = 'train_end_acc')\r\n",
        "val_start_acc = tf.keras.metrics.CategoricalAccuracy(name = 'val_start_acc')\r\n",
        "val_end_acc = tf.keras.metrics.CategoricalAccuracy(name = 'val_end_acc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp9ojYdzUzwG"
      },
      "source": [
        "best_loss = 100 # we initialize a loss value for model checkpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fOKYFlzcwiW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed14ba82-a7b2-44f9-dad4-e558bfa8526c"
      },
      "source": [
        "for epoch in range(EPOCHS):\r\n",
        "    \r\n",
        "    # resetting the states of the loss and metrics\r\n",
        "    train_start_loss.reset_states()\r\n",
        "    train_end_loss.reset_states()\r\n",
        "    val_start_loss.reset_states()\r\n",
        "    val_end_loss.reset_states()\r\n",
        "    train_start_f1.reset_states()\r\n",
        "    train_end_f1.reset_states()\r\n",
        "    val_start_f1.reset_states()\r\n",
        "    val_end_f1.reset_states()\r\n",
        "    train_start_acc.reset_states()\r\n",
        "    train_end_acc.reset_states()\r\n",
        "    val_start_acc.reset_states()\r\n",
        "    val_end_acc.reset_states()\r\n",
        "    \r\n",
        "    # iterating over train data batch by batch\r\n",
        "    for text_seq, label_seq in tqdm(iterable = train_dataset, total = len(train_dataset)):\r\n",
        "        # train step\r\n",
        "        loss_start_, loss_end_, pred_out, gradients = train_step(bidaf_model, text_seq, label_seq, loss_function)\r\n",
        "        # adding loss to train loss\r\n",
        "        train_start_loss(loss_start_)\r\n",
        "        train_end_loss(loss_end_)\r\n",
        "        \r\n",
        "        # calculating f1 for batch\r\n",
        "        f1_start = f1_score(label_seq[0], pred_out[0])\r\n",
        "        f1_end = f1_score(label_seq[1], pred_out[1])\r\n",
        "        train_start_f1(f1_start)\r\n",
        "        train_end_f1(f1_end)\r\n",
        "        train_start_acc(label_seq[0], pred_out[0])\r\n",
        "        train_end_acc(label_seq[1], pred_out[1])\r\n",
        "    \r\n",
        "    # validation data\r\n",
        "    for text_seq_val, label_seq_val in valid_dataset:\r\n",
        "        # getting val output\r\n",
        "        loss_val_start, loss_val_end, pred_out_val = val_step(bidaf_model, text_seq_val, label_seq_val, loss_function)\r\n",
        "        \r\n",
        "        val_start_loss(loss_val_start)\r\n",
        "        val_end_loss(loss_val_end)\r\n",
        "        \r\n",
        "        # calculating metric\r\n",
        "        f1_start_val = f1_score(label_seq_val[0], pred_out_val[0])\r\n",
        "        f1_end_val = f1_score(label_seq_val[1], pred_out_val[1])\r\n",
        "        val_start_f1(f1_start_val)\r\n",
        "        val_end_f1(f1_end_val)\r\n",
        "        val_start_acc(label_seq_val[0], pred_out_val[0])\r\n",
        "        val_end_acc(label_seq_val[1], pred_out_val[1])\r\n",
        "    \r\n",
        "   \r\n",
        "    # printing\r\n",
        "    template = '''Epoch {}, Train Start Loss: {:0.6f}, Train Start Acc : {:0.5f}, Start F1 Score: {:0.5f}, Train End Loss: {:0.6f}, Train End Acc : {:0.5f}, End F1 Score: {:0.5f},\r\n",
        "    Val Start Loss: {:0.6f}, Val Start Acc : {:0.5f}, Val Start F1 Score: {:0.5f}, Val End Loss: {:0.6f}, Val End Acc : {:0.5f}, Val End F1 Score: {:0.5f}'''\r\n",
        "\r\n",
        "    print(template.format(epoch + 1, train_start_loss.result(), train_start_acc.result(), train_start_f1.result(), \r\n",
        "                          train_end_loss.result(), train_end_acc.result(), train_end_f1.result(),\r\n",
        "                          val_start_loss.result(), val_start_acc.result(), val_start_f1.result(),\r\n",
        "                          val_end_loss.result(), val_end_acc.result(), val_end_f1.result()))\r\n",
        "\r\n",
        "\r\n",
        "    if (val_start_loss.result() + val_end_loss.result()) < best_loss:\r\n",
        "      print('Saving weights...')\r\n",
        "      bidaf_model.save_weights('drive/MyDrive/NLP/BIDAF/utils/models/weights/bidaf_weights')\r\n",
        "      print('\\n Done !')\r\n",
        "      best_loss = (val_start_loss.result() + val_end_loss.result())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6961/6961 [44:48<00:00,  2.59it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Train Start Loss: 3.713853, Train Start Acc : 0.21268, Start F1 Score: 0.09921, Train End Loss: 3.516613, Train End Acc : 0.23350, End F1 Score: 0.11051,\n",
            "    Val Start Loss: 2.201488, Val Start Acc : 0.44312, Val Start F1 Score: 0.28122, Val End Loss: 1.988928, Val End Acc : 0.47941, Val End F1 Score: 0.32824\n",
            "Saving weights...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/6961 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Done !\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6961/6961 [44:16<00:00,  2.62it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2, Train Start Loss: 2.672784, Train Start Acc : 0.42808, Start F1 Score: 0.37917, Train End Loss: 2.524039, Train End Acc : 0.45798, End F1 Score: 0.42111,\n",
            "    Val Start Loss: 1.754525, Val Start Acc : 0.53219, Val Start F1 Score: 0.45609, Val End Loss: 1.582747, Val End Acc : 0.57153, Val End F1 Score: 0.50670\n",
            "Saving weights...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/6961 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Done !\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6961/6961 [44:25<00:00,  2.61it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3, Train Start Loss: 2.402298, Train Start Acc : 0.48576, Start F1 Score: 0.46137, Train End Loss: 2.250612, Train End Acc : 0.51869, End F1 Score: 0.50846,\n",
            "    Val Start Loss: 1.659768, Val Start Acc : 0.55321, Val Start F1 Score: 0.51884, Val End Loss: 1.506444, Val End Acc : 0.58600, Val End F1 Score: 0.55114\n",
            "Saving weights...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/6961 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Done !\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6961/6961 [44:18<00:00,  2.62it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4, Train Start Loss: 2.203818, Train Start Acc : 0.52497, Start F1 Score: 0.51792, Train End Loss: 2.074208, Train End Acc : 0.55607, End F1 Score: 0.56182,\n",
            "    Val Start Loss: 1.655275, Val Start Acc : 0.55401, Val Start F1 Score: 0.53658, Val End Loss: 1.502723, Val End Acc : 0.59065, Val End F1 Score: 0.57162\n",
            "Saving weights...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/6961 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Done !\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6961/6961 [44:25<00:00,  2.61it/s]\n",
            "  0%|          | 0/6961 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5, Train Start Loss: 2.055331, Train Start Acc : 0.55568, Start F1 Score: 0.55691, Train End Loss: 1.939746, Train End Acc : 0.58337, End F1 Score: 0.60004,\n",
            "    Val Start Loss: 1.702703, Val Start Acc : 0.55619, Val Start F1 Score: 0.54585, Val End Loss: 1.561018, Val End Acc : 0.59255, Val End F1 Score: 0.58075\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6961/6961 [44:28<00:00,  2.61it/s]\n",
            "  0%|          | 0/6961 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6, Train Start Loss: 1.918788, Train Start Acc : 0.58545, Start F1 Score: 0.59501, Train End Loss: 1.813458, Train End Acc : 0.60949, End F1 Score: 0.63124,\n",
            "    Val Start Loss: 1.731502, Val Start Acc : 0.55321, Val Start F1 Score: 0.55223, Val End Loss: 1.629714, Val End Acc : 0.58950, Val End F1 Score: 0.59012\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6961/6961 [44:25<00:00,  2.61it/s]\n",
            "  0%|          | 0/6961 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7, Train Start Loss: 1.824023, Train Start Acc : 0.60426, Start F1 Score: 0.61978, Train End Loss: 1.720178, Train End Acc : 0.62920, End F1 Score: 0.65666,\n",
            "    Val Start Loss: 1.750128, Val Start Acc : 0.54965, Val Start F1 Score: 0.54725, Val End Loss: 1.641849, Val End Acc : 0.59203, Val End F1 Score: 0.59088\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6961/6961 [44:30<00:00,  2.61it/s]\n",
            "  0%|          | 0/6961 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8, Train Start Loss: 1.731592, Train Start Acc : 0.62444, Start F1 Score: 0.64413, Train End Loss: 1.646126, Train End Acc : 0.64408, End F1 Score: 0.67681,\n",
            "    Val Start Loss: 1.887377, Val Start Acc : 0.54574, Val Start F1 Score: 0.55190, Val End Loss: 1.752178, Val End Acc : 0.58428, Val End F1 Score: 0.59076\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6961/6961 [44:26<00:00,  2.61it/s]\n",
            "  0%|          | 0/6961 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9, Train Start Loss: 1.646621, Train Start Acc : 0.64293, Start F1 Score: 0.66637, Train End Loss: 1.578775, Train End Acc : 0.65967, End F1 Score: 0.69311,\n",
            "    Val Start Loss: 1.933540, Val Start Acc : 0.53948, Val Start F1 Score: 0.54766, Val End Loss: 1.834540, Val End Acc : 0.57905, Val End F1 Score: 0.58306\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6961/6961 [44:29<00:00,  2.61it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10, Train Start Loss: 1.597884, Train Start Acc : 0.65529, Start F1 Score: 0.68230, Train End Loss: 1.528513, Train End Acc : 0.66967, End F1 Score: 0.70666,\n",
            "    Val Start Loss: 1.975476, Val Start Acc : 0.54396, Val Start F1 Score: 0.54932, Val End Loss: 1.815104, Val End Acc : 0.58163, Val End F1 Score: 0.58247\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wygC27fedajx"
      },
      "source": [
        "def print_predictions(batch):\r\n",
        "\r\n",
        "  idx = np.random.randint(BATCH_SIZE)\r\n",
        "  samples = valid_dataset[batch]\r\n",
        "\r\n",
        "  sequences, labels = samples\r\n",
        "\r\n",
        "  qw = sequences[0][idx]\r\n",
        "  cw = sequences[1][idx]\r\n",
        "  qc = sequences[2][idx]\r\n",
        "  cc = sequences[3][idx]\r\n",
        "\r\n",
        "  real_start = labels[0][idx]\r\n",
        "  real_end = labels[1][idx]\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  Function that takes record numbers as input and predicts the answer for that record\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  print('Question:')\r\n",
        "  for i in qw:\r\n",
        "    if i == 0:\r\n",
        "      break\r\n",
        "    else:\r\n",
        "      print(tokenizer.index_word[i], end = ' ')\r\n",
        "\r\n",
        "  print('\\nContext:')\r\n",
        "  for i in cw:\r\n",
        "    if i == 0:\r\n",
        "      break\r\n",
        "    else:\r\n",
        "      print(tokenizer.index_word[i], end = ' ')\r\n",
        "      \r\n",
        "  print('\\nPredicted Answer:')\r\n",
        "  _qw = qw.reshape(1, qw.shape[0])\r\n",
        "  _cw = cw.reshape(1, cw.shape[0])\r\n",
        "  _qc = np.expand_dims(qc, axis = 0)\r\n",
        "  _cc = np.expand_dims(cc, axis = 0)\r\n",
        "  start, end = bidaf_model.predict((_qw, _cw, _qc, _cc))\r\n",
        "  start = start.argmax()\r\n",
        "  end = end.argmax() + 1\r\n",
        "\r\n",
        "  if start > end:\r\n",
        "    start = end\r\n",
        "    end = start\r\n",
        "\r\n",
        "  for i in range(start, end ):\r\n",
        "    print(tokenizer.index_word[cw[i]], end = ' ')\r\n",
        "  print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TOn5DDbddfq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e559f8df-77c7-449d-bf91-35b8ab663368"
      },
      "source": [
        "data_points = [8,15,52,152,332]\r\n",
        "for i in data_points:\r\n",
        "  print_predictions(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question:\n",
            "how many consecutive years was american idol the top rated show ? \n",
            "Context:\n",
            "seasonal rankings ( based on average total viewers per episode ) of american idol . it holds the distinction of having the longest winning streak in the nielsen annual television ratings ; it became the highest-rated of all television programs in the united states overall for an unprecedented seven consecutive years , or eight consecutive ( and total ) years when either its performance or result show was ranked number one overall . \n",
            "Predicted Answer:\n",
            "seven consecutive \n",
            "\n",
            "Question:\n",
            "who owned the rights to oswald ? \n",
            "Context:\n",
            "universal owned the rights to the `` oswald the lucky rabbit '' character , although walt disney and ub iwerks had created oswald , and their films had enjoyed a successful theatrical run . after charles mintz had unsuccessfully demanded that disney accept a lower fee for producing the property , mintz produced the films with his own group of animators . instead , disney and iwerks created mickey mouse who in 1928 stared in the first `` sync '' sound animated short , steamboat willie . this moment effectively launched walt disney studios ' foothold , while universal became a minor player in film animation . universal subsequently severed its link to mintz and formed its own in-house animation studio to produce oswald cartoons headed by walter lantz . \n",
            "Predicted Answer:\n",
            "universal owned \n",
            "\n",
            "Question:\n",
            "a referee gives out a yellow card and writes down the players name in his notebook which is called being what ? \n",
            "Context:\n",
            "the referee may punish a player 's or substitute 's misconduct by a caution ( yellow card ) or dismissal ( red card ) . a second yellow card at the same game leads to a red card , and therefore to a dismissal . a player given a yellow card is said to have been `` booked '' , the referee writing the player 's name in his official notebook . if a player has been dismissed , no substitute can be brought on in their place . misconduct may occur at any time , and while the offences that constitute misconduct are listed , the definitions are broad . in particular , the offence of `` unsporting behaviour '' may be used to deal with most events that violate the spirit of the game , even if they are not listed as specific offences . a referee can show a yellow or red card to a player , substitute or substituted player . non-players such as managers and support staff can not be shown the yellow or red card , but may be expelled from the technical area if they fail to conduct themselves in a responsible manner . \n",
            "Predicted Answer:\n",
            "booked '' \n",
            "\n",
            "Question:\n",
            "the concentration on students to live honorable lives is an example of what form of thought ? \n",
            "Context:\n",
            "early modern universities initially continued the curriculum and research of the middle ages : natural philosophy , logic , medicine , theology , mathematics , astronomy ( and astrology ) , law , grammar and rhetoric . aristotle was prevalent throughout the curriculum , while medicine also depended on galen and arabic scholarship . the importance of humanism for changing this state-of-affairs can not be underestimated . once humanist professors joined the university faculty , they began to transform the study of grammar and rhetoric through the studia humanitatis . humanist professors focused on the ability of students to write and speak with distinction , to translate and interpret classical texts , and to live honorable lives . other scholars within the university were affected by the humanist approaches to learning and their linguistic expertise in relation to ancient texts , as well as the ideology that advocated the ultimate importance of those texts . professors of medicine such as niccolò leoniceno , thomas linacre and william cop were often trained in and taught from a humanist perspective as well as translated important ancient medical texts . the critical mindset imparted by humanism was imperative for changes in universities and scholarship . for instance , andreas vesalius was educated in a humanist fashion before producing a translation of galen , whose ideas he verified through his own dissections . in law , andreas alciatus infused the corpus juris with a humanist perspective , while jacques cujas humanist writings were paramount to his reputation as a jurist . philipp melanchthon cited the works of erasmus as a highly influential guide for connecting theology back to original texts , which was important for the reform at protestant universities . galileo galilei , who taught at the universities of pisa and padua , and martin luther , who taught at the university of wittenberg ( as did melanchthon ) , also had humanist training . the task of the humanists was to slowly permeate the university ; to increase the humanist presence in professorships and chairs , syllabi and textbooks so that published works would demonstrate the humanistic ideal of science and scholarship . \n",
            "Predicted Answer:\n",
            "rhetoric . aristotle was prevalent throughout the curriculum , while medicine also depended on galen and arabic scholarship . the importance of humanism for changing this state-of-affairs can not be underestimated . once humanist professors joined the university faculty , they began to transform the study of grammar and rhetoric through the studia humanitatis . humanist professors focused on the ability of students to write and speak with distinction , to translate and interpret classical texts , \n",
            "\n",
            "Question:\n",
            "what is the result of the programmer making a mistake ? \n",
            "Context:\n",
            "software faults occur through the following processes . a programmer makes an error ( mistake ) , which results in a defect ( fault , bug ) in the software source code . if this defect is executed , in certain situations the system will produce wrong results , causing a failure . not all defects will necessarily result in failures . for example , defects in dead code will never result in failures . a defect can turn into a failure when the environment is changed . examples of these changes in environment include the software being run on a new computer hardware platform , alterations in source data , or interacting with different software . a single defect may result in a wide range of failure symptoms . \n",
            "Predicted Answer:\n",
            "software source code . \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLBhzlJNBCKe"
      },
      "source": [
        "# class BIDAF():\r\n",
        "\r\n",
        "#   \"\"\"\r\n",
        "#   the BIDAF model\r\n",
        "#   \"\"\"\r\n",
        "\r\n",
        "#   def __init__(self, model, path_tokenizer, path_char_tokenizer = None, char_level = True):\r\n",
        "\r\n",
        "#     self.QUESTION_MAXLEN = 20\r\n",
        "#     self.CONTEXT_MAXLEN = 300\r\n",
        "#     self.WORD_MAXLEN = 15\r\n",
        "#     self.char_level = char_level\r\n",
        "#     #self.path_model = path_model\r\n",
        "#     self.path_tokenizer = path_tokenizer\r\n",
        "#     self.path_char_tokenizer = path_char_tokenizer\r\n",
        "#     self.model = model\r\n",
        "#     with open(self.path_tokenizer, 'rb') as handle:\r\n",
        "#       self.tokenizer = pickle.load(handle)\r\n",
        "#     if self.char_level:\r\n",
        "#       with open(self.path_char_tokenizer, 'rb') as handle:\r\n",
        "#         self.char_tokenizer = pickle.load(handle)\r\n",
        "  \r\n",
        "#   def _get_tokens(self):\r\n",
        "\r\n",
        "#     self.question = self.tokenizer.texts_to_sequences([self.question])\r\n",
        "#     self.context = self.tokenizer.texts_to_sequences([self.context])\r\n",
        "\r\n",
        "#   def _get_padded_sequences(self):\r\n",
        "\r\n",
        "#     self.question = tf.keras.preprocessing.sequence.pad_sequences(self.question, maxlen = self.QUESTION_MAXLEN, padding = 'post')\r\n",
        "#     self.context = tf.keras.preprocessing.sequence.pad_sequences(self.context, maxlen = self.CONTEXT_MAXLEN, padding = 'post')\r\n",
        "\r\n",
        "#   def predict(self, question, context):\r\n",
        "\r\n",
        "#     self._q = question\r\n",
        "#     self._c = context\r\n",
        "\r\n",
        "#     self.question = question\r\n",
        "#     self.context = context\r\n",
        "#     self._get_tokens()\r\n",
        "#     self._get_padded_sequences()\r\n",
        "\r\n",
        "#     if self.char_level:\r\n",
        "#       self.__get_tokens()\r\n",
        "#       self.__get_padded_sequences()\r\n",
        "#       start, end = self.model.predict([self.question, self.context, self.question_char, self.context_char])\r\n",
        "#     else:\r\n",
        "#       start, end = self.model.predict([self.question, self.context])\r\n",
        "\r\n",
        "#     for i in range(start.argmax(), end.argmax() + 1):\r\n",
        "#       print(self.tokenizer.index_word[self.context[0][i]], end = ' ')\r\n",
        "\r\n",
        "#   def __get_tokens(self):\r\n",
        "\r\n",
        "#     self._question_char = []\r\n",
        "#     self._context_char = []\r\n",
        "\r\n",
        "#     for question, context in zip(self._q, self._c):\r\n",
        "#       _q = self.char_tokenizer.texts_to_sequences(question)\r\n",
        "#       _c = self.char_tokenizer.texts_to_sequences(context)\r\n",
        "#       self._question_char.append(_q)\r\n",
        "#       self._context_char.append(_c)\r\n",
        "\r\n",
        "#   def __get_padded_sequences(self):\r\n",
        "\r\n",
        "#     # pad question at the character level\r\n",
        "#     v = tf.keras.preprocessing.sequence.pad_sequences(self._question_char, padding = 'post', maxlen = self.WORD_MAXLEN)\r\n",
        "#     to_add = self.QUESTION_MAXLEN - v.shape[0]\r\n",
        "#     add = np.zeros((to_add, WORD_MAXLEN))\r\n",
        "#     arr = np.vstack([v,add])\r\n",
        "#     self.question_char = arr\r\n",
        "\r\n",
        "#     # pad context at the character level\r\n",
        "#     v = tf.keras.preprocessing.sequence.pad_sequences(self._context_char, padding = 'post', maxlen = self.WORD_MAXLEN)\r\n",
        "#     to_add = self.CONTEXT_MAXLEN - v.shape[0]\r\n",
        "#     add = np.zeros((to_add, WORD_LEN))\r\n",
        "#     arr = np.vstack([v,add])\r\n",
        "#     self.context_char = arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZPHlx49DzRO"
      },
      "source": [
        "# bidaf = BIDAF(\r\n",
        "#     model = model,\r\n",
        "#     path_tokenizer = 'drive/MyDrive/NLP/data/tokenizer.pickle',\r\n",
        "#     path_char_tokenizer = 'drive/MyDrive/NLP/data/char_tokenizer.pickle',\r\n",
        "#     char_level = True\r\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3IzPCNqEO0j"
      },
      "source": [
        "# question = 'In what country is Normandy located?'\r\n",
        "# context = \"The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse ('Norman' comes from 'Norseman') raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVSH0HDGERdT"
      },
      "source": [
        "# bidaf.predict(question, context)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9Sxh-VBWXOj"
      },
      "source": [
        "**FURTHER WORK**:\r\n",
        "* try with GRU instead of LSTM (GRU are usually faster)"
      ]
    }
  ]
}